# ğŸ§  IntelliScraper

<div align="center">

![Python](https://img.shields.io/badge/Python-3.8+-3776AB?style=for-the-badge&logo=python&logoColor=white)
![Streamlit](https://img.shields.io/badge/Streamlit-FF4B4B?style=for-the-badge&logo=streamlit&logoColor=white)
![Selenium](https://img.shields.io/badge/Selenium-43B02A?style=for-the-badge&logo=selenium&logoColor=white)
![OpenAI](https://img.shields.io/badge/OpenAI-412991?style=for-the-badge&logo=openai&logoColor=white)
![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)

**AI-Powered Web Scraping & Analysis Platform**

[Features](#-features) â€¢ [Installation](#-installation) â€¢ [Usage](#-usage)

</div>

---

## ğŸ“‹ Overview

**IntelliScraper** is an advanced AI-powered web scraping tool combining real-time search, intelligent content extraction, and interactive data querying. Built with Streamlit and integrated with multiple AI models (Ollama, Groq, OpenAI, Cohere).

## âœ¨ Features

- ğŸ” **Simple Interface**: Clean, intuitive Streamlit UI
- ğŸ¤– **AI-Powered**: Extract structured data using LLM models
- ğŸ“Š **Auto-Save**: All data automatically saved
- ğŸ›¡ï¸ **Anti-Bot**: User-agent rotation, intelligent delays
- ğŸ’¾ **Local Storage**: Data saved in organized folders
- ğŸ“ **Logging**: Track all operations

## ğŸš€ Quick Start

```bash
# Clone repository
git clone https://github.com/harsh2025-sketch/webscraper-3.0.git
cd webscraper-3.0

# Setup environment
python -m venv venv
venv\Scripts\activate  # Windows
source venv/bin/activate  # Linux/Mac

# Install dependencies
pip install -r requirements.txt

# Run the app
streamlit run main.py
```

## ğŸ”§ Prerequisites

- Python 3.8+
- Chrome/Chromium browser
- API Keys (optional): OpenAI, Cohere, Groq

## ğŸ“¦ Configuration

Create `.env` file:
```env
OPENAI_API_KEY=your_key
COHERE_API_KEY=your_key
GROQ_API_KEY=your_key
```

## ğŸ’¡ Usage

**Simple 2-Step Process:**
1. Enter website URL â†’ Click "Scrape Website"
2. Describe what to extract â†’ Click "Extract"

All data is automatically saved in the `data/` folder.

## ğŸ—ï¸ Project Structure

```
IntelliScraper/
â”œâ”€â”€ main.py           # Simple Streamlit UI
â”œâ”€â”€ scrape.py         # Web scraping engine
â”œâ”€â”€ parse.py          # AI parsing
â”œâ”€â”€ model.py          # AI models
â”œâ”€â”€ utils.py          # Utilities
â”œâ”€â”€ requirements.txt  # Dependencies
â””â”€â”€ setup.py         # Setup script
```

## ğŸ“Š Data Storage

- **Raw**: `data/raw_data/`
- **Processed**: `data/processed_data/`
- **Logs**: `logs/`

## ğŸ› ï¸ Advanced Features

- Automatic ChromeDriver management
- Exponential backoff retry logic
- Content chunking for large documents
- Real-time query categorization
- Structured data extraction

## ğŸ› Troubleshooting

**Import errors**: `pip install -r requirements.txt`  
**ChromeDriver**: Auto-downloaded, ensure Chrome installed  
**Ollama**: Install from [ollama.ai](https://ollama.ai) â†’ `ollama pull llama3`

## ğŸ¤ Contributing

Fork â†’ Create branch â†’ Commit â†’ Push â†’ Pull Request

## ğŸ“„ License

MIT License
---

<div align="center">

â­ **Star this repo if you find it useful!** â­


</div>
